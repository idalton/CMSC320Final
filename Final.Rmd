---
title: "Final"
author: "Ian Dalton"
date: "May 18, 2018"
output: 
  html_document: 
    toc: yes
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), 'index.html')) })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(dplyr)
library(ggplot2)
library(stringr)
library(DT)
library(tidyr)
library(readr)
library(leaflet)
library(lubridate)
```

# Name TBD
I will think of a cool name later.  




walk users through the entire data science pipeline:  
- data curation,  
- parsing, and management  
- exploratory data analysis  
- hypothesis testing and  
- machine learning to provide analysis  
- and then the curation of a message or messages covering insights learned during the tutorial.  


## Introduction  

**DATA**

While browsing datasets on kaggle, I encountered a dataset on honey production recorded from the National Agricultural Statistics Service which can be found here. 
The dataset included production data from 1998 to 2012.    
I found that the dataset was created from a series of `csv` files contained within zip files for years 1998-2012.   However the National Agricultural Statistics Service website has data from 1986 and onward in the form of text files.  
I thought this would be a good oppurtunity showcase some data scraping and tidying as well to expand the amount of data available for analysis later.

Also I can export the data frames I make and post them to kaggle as an expansion of the data set that I prevously came across

## Data Scraping and Tidying

I encourage you to look at the text file links below to get a better understanding of the format of the text files and to see what we are working with. You may notice that the text format of the data in the 2008-2012 file is slightly different from the other files. We will need to address this later by changing how we scrape the data from that file in particular.

Also each of the tables have rows for totals at the bottom. I will not be taking the totals data from the files because I only want individual state data from each year. Additionally some states are not listed individually and get clumped together in the `Oth Sts` row.

I may include this data such that i can have at least some data from rather than none from the unincluded states
Or
I may not include this data since I only want individual state data and

what to do about HI and AK alaska
only contigous 48?
ake average

For the most part the other files have a the same format so we can reuse the code to scrape the data from them.

A couple notes about how I approached scraping the data before I get to the code:
- All the tables start with data from Alabama (AL)
- All the tables end with data from Wyoming (WY)
- the table order corresponds to the year order


I downloaded all the text documents locally and gave them descriptive names before trying to scrape the data within.

```{r test}
# Column names taken from the text files
headers <- c(
  "state",
	"numcolonies", # 1,000s
	"yieldpercolony", # in pounds
	"production",# in 1000 pounds
	"stocks", # 1,000 Pounds
	"avgprice", # cents
	"value" #$1,000s
  )  

honey_1986_1992 <- read_lines ("HoneyData_1986-1992.txt")
honey_1993_1997 <- read_lines ("HoneyData_1993-1997.txt")
honey_1998_2002 <- read_lines ("HoneyData_1998-2002.txt")
honey_2003_2007 <- read_lines ("HoneyData_2003-2007.txt")



getdata <- function(text,year) {
  start_lines <- c(grep("AL",text))
  end_lines <- c(grep("WY",text))
  othersts_lines <- c(grep("Sts",text))  
  
  df = NULL
  for (index in 1:length(start_lines)){
    # data[[index]] <- honey_1986_1992[start_lines[index]:end_lines[index]]
    table <- text[start_lines[index]:end_lines[index]]
    
    table <- table %>% 
      str_replace_all(":", "") %>%
      str_replace_all("\\s\\s*", " " ) %>%
      data_frame() %>%
      separate(1,sep = " ",headers, extra="drop") %>% # make columns with the given names
      mutate(year = rep(year+index))
    
      # need to adjust varaiable values
    
    df = rbind(df,table)
  }
  df
}

honey_1986_1992df <- getdata(honey_1986_1992,1985)
honey_1986_1992df

honey_1993_1997df <- getdata(honey_1993_1997,1992)
honey_1993_1997df

honey_1998_2002df <- getdata(honey_1998_2002,1997)
honey_1998_2002df

honey_2003_2007df <- getdata(honey_2003_2007,2002)
honey_2003_2007df




# h1987 <- honey_1986_1992[start_lines[2]:end_lines[2]]
# 
# h1987 <- h1987 %>% 
#   str_replace_all(":", "") %>%
#   str_replace_all("\\s\\s*", " " ) %>%
#   trimws(which = c("both"))
#   data_frame() %>%
#   separate(1,sep = " ",headers, extra="drop") %>%
#   mutate(year = rep(1986 + 9))
# 
# h1987

# df



```

##Plots

there will also be plots because who doesnt like well formated plots?  

```{r pressure, echo=FALSE}
plot(pressure)
```

test 

```{r include=FALSE}
options(tibble.width = Inf)
```


Lets test some demonstration of data

### example table {.tabset}

#### table1
There is an example of a dynamic data table possible because of web hosting the html output yippee.

```{r, result='asis', echo=FALSE}
datatable(cars, style="bootstrap", class="table-condensed", options = list(dom = 'tp',scrollX = TRUE))
```

#### table2

```{r, result='asis', echo=FALSE}
datatable(pressure, style="bootstrap", class="table-condensed", options = list(dom = 'tp'))
```


Stay tuned!